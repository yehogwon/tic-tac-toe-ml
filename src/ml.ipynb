{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tic-tac-toe/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human: O, Computer: X\n",
    "# Blank: 0, Human: 1, Computer: -1\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class TicTacToe():\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=np.int32)\n",
    "    \n",
    "    def place(self, action: int, player: int) -> bool:\n",
    "        if self.board[action // 3, action % 3] == 0:\n",
    "            self.board[action // 3, action % 3] = player\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def available(self) -> np.ndarray:\n",
    "        return np.where(self.board == 0)[0]\n",
    "    \n",
    "    def _check(self, v: List[int]) -> bool:\n",
    "        _sum = sum(v)\n",
    "        if _sum == 3: \n",
    "            return 1\n",
    "        elif _sum == -3:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def win(self) -> int: # check the winner of the game. If it's not done, return -1. \n",
    "        vecs: list = [self.board.tolist()[0], self.board.T.tolist()[0], self.board.diagonal(), np.flip(self.board, 1).diagonal()]\n",
    "        \n",
    "        for vec in vecs: \n",
    "            checked = self._check(vec)\n",
    "            if checked != 0:\n",
    "                return checked\n",
    "        return -1\n",
    "    \n",
    "    def all_occupied(self) -> bool: \n",
    "        return np.square(self.board).sum() == 9\n",
    "    \n",
    "    def done(self) -> bool: \n",
    "        return self.win() != -1 or self.all_occupied()\n",
    "    \n",
    "    def render(self, player: Optional[int] = None): \n",
    "        if player is None: \n",
    "            assert abs(player) == 1, 'player must be 1 or -1'\n",
    "            print('=' * 3, 'human' if player == 1 else 'computer', '=' * 3)\n",
    "        for row in self.board: \n",
    "            print(' '.join([str(c) for c in row.tolist()]))\n",
    "        print('=' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module): \n",
    "    def __init__(self, device) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=2, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=2, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=2, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=2, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(1600, 9)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.fc(x.view(x.size(0), -1))\n",
    "        return x\n",
    "    \n",
    "    def action(self, state: torch.Tensor) -> int: \n",
    "        x = self.forward(state)\n",
    "        x = self.softmax(x)\n",
    "        # x[torch.where(state.view(state.size(0), -1).square() == 1)] = 0\n",
    "        x[np.where(state.view(state.size(0), -1).square() == 1)] = 0\n",
    "        return torch.argmax(x).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_loop(agent: Agent, human_first=True, manual=False, random=False): \n",
    "    actions = []\n",
    "\n",
    "    game = TicTacToe()\n",
    "    turn = 1 if human_first else -1\n",
    "\n",
    "    while not game.done(): \n",
    "        if manual: \n",
    "            if turn == 1: \n",
    "                if random: \n",
    "                    action = np.random.choice(game.available())\n",
    "                else: \n",
    "                    action = int(input('Enter your action: '))\n",
    "                if not game.place(action, 1): \n",
    "                    break\n",
    "            else: \n",
    "                action = agent.action(torch.from_numpy(game.board).view(1, 1, 3, 3).float().to(device))\n",
    "                game.place(action, turn)\n",
    "            if not random: \n",
    "                game.render(turn)\n",
    "        else: \n",
    "            action = agent.action(torch.from_numpy(game.board).view(1, 1, 3, 3).float().to(device))\n",
    "            game.place(action, turn)\n",
    "        actions.append(action)\n",
    "        turn *= -1\n",
    "    return game.win(), human_first, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(device).to(device)\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(agent.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 374.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# FIXME: Update the training manner (Enhance the self-play method)\n",
    "n_iteration = 10000\n",
    "desc = ''\n",
    "for i in tqdm(range(n_iteration), desc=desc):\n",
    "    # winner, human_first, actions = game_loop(agent, bool(random.getrandbits(1)))\n",
    "    winner, human_first, actions = game_loop(agent, False)\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    my_board = torch.FloatTensor(np.zeros((3, 3)))\n",
    "    oppo_board = torch.FloatTensor(np.zeros((3, 3)))\n",
    "    \n",
    "    if winner != (1 if human_first else -1): \n",
    "        actions = actions[1:]\n",
    "    for i, action in enumerate(actions): \n",
    "        my_board[action // 3, action % 3] = winner * coeff\n",
    "        oppo_board[action // 3, action % 3] = -winner * coeff\n",
    "        x_train.append(my_board if i % 2 == 0 else oppo_board)\n",
    "        y_train.append([action])\n",
    "        winner *= -1\n",
    "    \n",
    "    x_train = torch.stack(x_train).to(device)\n",
    "    x_train = x_train.view(x_train.size(0), 1, 3, 3)\n",
    "    y_train = torch.LongTensor(y_train, device=device).squeeze()\n",
    "\n",
    "    y_hat = agent(x_train)\n",
    "    cost = criteria(y_hat, y_train)\n",
    "    desc = f'{i}/{n_iteration} : {winner} : {cost:.4f}'\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:14<00:00, 3333.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winning rate is 0.91444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "win_count = [0, 0]\n",
    "for _ in tqdm(range(50000)): \n",
    "    win_count[(game_loop(agent, human_first=True, manual=True, random=True)[0] + 1) // 2] += 1\n",
    "print('The winning rate is', win_count[0] / sum(win_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 1\n",
      "0 0 0\n",
      "==========\n",
      "0 0 -1\n",
      "0 0 1\n",
      "0 0 0\n",
      "==========\n",
      "0 0 -1\n",
      "0 1 1\n",
      "0 0 0\n",
      "==========\n",
      "0 0 -1\n",
      "-1 1 1\n",
      "0 0 0\n",
      "==========\n",
      "0 1 -1\n",
      "-1 1 1\n",
      "0 0 0\n",
      "==========\n",
      "-1 1 -1\n",
      "-1 1 1\n",
      "0 0 0\n",
      "==========\n",
      "-1 1 -1\n",
      "-1 1 1\n",
      "0 1 0\n",
      "==========\n",
      "-1 1 -1\n",
      "-1 1 1\n",
      "-1 1 0\n",
      "==========\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yeho/Programming/Projects/Sci-War/tic-tac-toe-ml/src/ml.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yeho/Programming/Projects/Sci-War/tic-tac-toe-ml/src/ml.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m game_loop(agent, human_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, manual\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, random\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;32m/Users/yeho/Programming/Projects/Sci-War/tic-tac-toe-ml/src/ml.ipynb Cell 9\u001b[0m in \u001b[0;36mgame_loop\u001b[0;34m(agent, human_first, manual, random)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeho/Programming/Projects/Sci-War/tic-tac-toe-ml/src/ml.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(game\u001b[39m.\u001b[39mavailable())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeho/Programming/Projects/Sci-War/tic-tac-toe-ml/src/ml.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yeho/Programming/Projects/Sci-War/tic-tac-toe-ml/src/ml.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(\u001b[39minput\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mEnter your action: \u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeho/Programming/Projects/Sci-War/tic-tac-toe-ml/src/ml.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m game\u001b[39m.\u001b[39mplace(action, \u001b[39m1\u001b[39m): \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeho/Programming/Projects/Sci-War/tic-tac-toe-ml/src/ml.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "game_loop(agent, human_first=True, manual=True, random=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tic-tac-toe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a62d3f485e9e293ebedd431e6328b2a88bbc776b5fec9adececcb4c370d22f0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
